{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework set #2 Problem #7: Binary Classification ECE246 \n",
    "\n",
    "Please follow our instructions in the same order to solve the binary classification problem.\n",
    "\n",
    "Please print out the entire results and codes when completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import csv\n",
    "from data_load import load\n",
    "import scipy.io as io\n",
    "# Load matplotlib images inline\n",
    "%matplotlib inline\n",
    "\n",
    "# These are important for reloading any code you write in external .py files.\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load the dataset from disk and perform preprocessing to prepare it for the linear regression problem.   \n",
    "\"\"\"\n",
    "train = io.loadmat('mnist_train')\n",
    "test = io.loadmat('mnist_test')\n",
    "X_train = train['X_train']\n",
    "y_train = np.transpose(train['y_train'])\n",
    "X_test = test['X_test']\n",
    "y_test = np.transpose(test['y_test'])\n",
    "\n",
    "print('Train data shape: ', X_train.shape)\n",
    "print('Train target shape: ', y_train.shape)\n",
    "print('Test data shape: ',X_test.shape)\n",
    "print('Test target shape: ',y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Visualize a point in the dataset\n",
    "index = 4000\n",
    "X = np.array(X_train[index], dtype='uint8')\n",
    "X = X.reshape((28, 28))\n",
    "fig = plt.figure()\n",
    "plt.imshow(X, cmap='gray')\n",
    "plt.show()\n",
    "fig.savefig('Sample.pdf')\n",
    "if y_train[index] == 1:\n",
    "    label = 3\n",
    "else:\n",
    "    label = 2\n",
    "print('label is', label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Perceptron\n",
    "In the following cells, you will build Perceptron Algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = X_train.shape[0] # Number of data point\n",
    "d = X_train.shape[1] # Number of features\n",
    "loss_hist = []\n",
    "W = np.zeros((d,1))\n",
    "# ================================================================ #\n",
    "# YOUR CODE HERE:\n",
    "# Implement the perceptron Algorithm and compute the number of misclassified points at each training step\n",
    "# ================================================================ #\n",
    "\n",
    "\n",
    "# ================================================================ #\n",
    "# END YOUR CODE HERE\n",
    "# ================================================================ #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the percentage of misclassified points in the test data for perceptron\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Logistic Regression\n",
    "\n",
    "In the following cells, you will build a logistic regression. You will implement its loss function, then subsequently train it with gradient descent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Logistic import Logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete loss_and_grad function in Logistic.py file and test your results.\n",
    "N,d = X_train.shape\n",
    "logistic = Logistic(d=d, reg_param=0)\n",
    "loss, grad = logistic.loss_and_grad(X_train,y_train)\n",
    "print('Loss function=',loss)\n",
    "print(np.linalg.norm(grad,ord=2)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete train_LR function in Logisitc.py file\n",
    "loss_history, w = logistic.train_LR(X_train,y_train, eta=1e-6,batch_size=50, num_iters=5000)\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(loss_history)\n",
    "plt.xlabel('iterations')\n",
    "plt.ylabel('Loss function')\n",
    "plt.show()\n",
    "fig.savefig('LR_loss_hist.pdf')\n",
    "print(np.linalg.norm(w,ord=2)**2)\n",
    "print(loss_history[4999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete predict function in Logisitc.py file and compute the percentage of misclassified points in the test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Batch = [1, 50 , 100, 300]\n",
    "test_err = np.zeros((len(Batch),1))\n",
    "# ================================================================ #\n",
    "# YOUR CODE HERE:\n",
    "# Train the Logistic regression for different batch size Avergae the test error over 10 times\n",
    "# ================================================================ #\n",
    "for t in range (0,10):\n",
    "    for m in range(0,len(Batch)):\n",
    "        \n",
    "\n",
    "# ================================================================ #\n",
    "# END YOUR CODE HERE\n",
    "# ================================================================ #\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train SVM\n",
    "\n",
    "In the following cells, you will build SVM. You will implement its loss function, then subsequently train it with mini-batch gradient descent. You will choose the learning rate of gradient descent to optimize its classification performance. Finally, you will get the best regularization parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SVM import SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete loss_and_grad function in SVM.py file and test your results.\n",
    "N,d = X_train.shape\n",
    "svm = SVM(d=d, reg_param=0)\n",
    "loss, grad = svm.loss_and_grad(X_train,y_train)\n",
    "print('Loss function=',loss)\n",
    "print(np.linalg.norm(grad,ord=2)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete train_svm function in SVM.py file \n",
    "loss_history, w = svm.train_svm(X_train,y_train, eta=1e-6,batch_size=50, num_iters=5000)\n",
    "fig = plt.figure()\n",
    "plt.plot(loss_history)\n",
    "plt.xlabel('iterations')\n",
    "plt.ylabel('Loss function')\n",
    "plt.show()\n",
    "fig.savefig('svm_loss_hist.pdf')\n",
    "print(np.linalg.norm(w,ord=2)**2)\n",
    "print(loss_history[4999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete predict function in SVM.py file and compute the percentage of misclassified points in the test data\n",
    "y_pred = svm.predict(X_test)\n",
    "test_err = np.sum((y_test!=y_pred))*100/X_test.shape[0]\n",
    "print(test_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Batch = [1, 50 , 100, 300]\n",
    "test_err = np.zeros((len(Batch),1))\n",
    "# ================================================================ #\n",
    "# YOUR CODE HERE:\n",
    "# Train the SVM for different batch size Avergae the test error over 10 times\n",
    "# ================================================================ #\n",
    "for t in range (0,10):\n",
    "    for m in range(0,len(Batch)):\n",
    "        \n",
    "\n",
    "# ================================================================ #\n",
    "# END YOUR CODE HERE\n",
    "# ================================================================ #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
