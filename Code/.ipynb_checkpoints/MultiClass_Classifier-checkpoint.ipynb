{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework set #3 Problem #3: Multi-Class Logistic Regression and Adaboost ECE246 \n",
    "\n",
    "Please follow our instructions in the same order to solve the linear regresssion problem.\n",
    "\n",
    "Please print out the entire results and codes when completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # for doing most of our calculations\n",
    "import matplotlib.pyplot as plt# for plotting\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from data_load import load_mnist\n",
    "import random\n",
    "import csv\n",
    "import scipy.io as io\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=load_mnist()\n",
    "\n",
    "print('Train data shape: ', X_train.shape)\n",
    "print('Train target shape: ', y_train.shape)\n",
    "print('Test data shape: ',X_test.shape)\n",
    "print('Test target shape: ',y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Visualize a point in the dataset\n",
    "index = 4000\n",
    "X = np.array(X_train[index], dtype='uint8')\n",
    "X = X.reshape((28, 28))\n",
    "fig = plt.figure()\n",
    "plt.imshow(X, cmap='gray')\n",
    "plt.show()\n",
    "fig.savefig('Sample.pdf')\n",
    "print('label is', y_train[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Multi-Class Logistic Regression\n",
    "\n",
    "In the following cells, you will build a Multi-Class logistic regression. You will implement its loss function, then subsequently train it with gradient descent. You will implement L1 norm regularization, and choose the best regularization parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Logistic import Logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Complete loss_and_grad function in Logistic.py file and test your results.\n",
    "num_classes = len(np.unique(y_train))\n",
    "num_features = X_train.shape[1]\n",
    "\n",
    "logistic = Logistic(dim=[num_classes,num_features], reg_param=0)\n",
    "loss, grad = logistic.loss_and_grad(X_train[:5000],y_train[:5000])\n",
    "print('Loss function=',loss)\n",
    "print('Frobenius norm of grad=',np.linalg.norm(grad))\n",
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Complete train_LR function in Logistic.py file \n",
    "loss_history, w = logistic.train_LR(X_train,y_train, eta=1e-7,batch_size=200, num_iters=1500)\n",
    "fig = plt.figure()\n",
    "plt.plot(loss_history)\n",
    "plt.xlabel('iterations')\n",
    "plt.ylabel('Loss function')\n",
    "plt.show()\n",
    "print(np.linalg.norm(w))\n",
    "print(loss_history[1499])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================ #\n",
    "# YOUR CODE HERE:\n",
    "#Complete predict function in Logistic.py file and compute the trainin error and the test error\n",
    "# ================================================================ #\n",
    "\n",
    "# ================================================================ #\n",
    "# END YOUR CODE HERE\n",
    "# ================================================================ #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = [0,1e-6,1e-3,1e-2,1e-1,1]\n",
    "train_err =np.zeros((len(reg),1))\n",
    "test_err =np.zeros((len(reg),1))\n",
    "# ================================================================ #\n",
    "# YOUR CODE HERE:\n",
    "# complete the following code to plot both the training and test loss in the same plot\n",
    "# for m range from 1 to 10\n",
    "# ================================================================ #\n",
    "for m in range(0,len(reg)):\n",
    "    pass\n",
    "    \n",
    "# ================================================================ #\n",
    "# END YOUR CODE HERE\n",
    "# ================================================================ #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 200\n",
    "N = X_train.shape[0]\n",
    "num_classes = len(np.unique(y_train))\n",
    "num_features = X_train.shape[1]\n",
    "train_err = np.zeros((T,1))\n",
    "test_err = np.zeros((T,1))\n",
    "# ================================================================ #\n",
    "# YOUR CODE HERE:\n",
    "# complete the following code to plot both the training and test loss in the same plot\n",
    "# as a function of number of classifiers T for Adaboost Algorithm. \n",
    "# ================================================================ #\n",
    "\n",
    "#Initialize\n",
    "\n",
    "for t in range(0,T):\n",
    "    #Train decision Tree\n",
    "    \n",
    "    #Compute error\n",
    "    \n",
    "    #Compute \\alpha\n",
    "    \n",
    "    #Update weights\n",
    "    \n",
    "    #Predict using Last t classifiers\n",
    "    \n",
    "    #compute test error and train error\n",
    "    \n",
    "# Plot test error and train error in the same plot vs T\n",
    "\n",
    "# ================================================================ #\n",
    "# END YOUR CODE HERE\n",
    "# ================================================================ #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
